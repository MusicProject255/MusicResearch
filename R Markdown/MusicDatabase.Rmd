---
title: "MusicDatabase"
author: Collin Smith, Conor Burrows, Jake Luedtke, Nicholas Melon
date: "January 25, 2017"
output: html_document
---
#Overview
  
In our group our main focus is to determine what genre is the most popular in each decade starting with 1900 and going up to 2016. We also are going to look at which genres are more popular in eruope compared to the U.S and if the words in a song title have a effect on how popular a song is. We are going to use music brainz to get the genre of a song, it's mood quality, and tempo. With this information we will be able to see the trends better in preffered music choice for each decade. In the end we may use the database to make a simple song finder based on your taste in genre, tempo, and mood.

Note: The first time a package is used, we provide URLs (commented) to some documentation for that package.


##Code used to get data
```{r eval=FALSE}
library(stringr)
### Some documentation for stringr:
##  https://cran.r-project.org/web/packages/stringr/index.html
##  https://cran.r-project.org/web/packages/stringr/stringr.pdf
#Get dataset and look at name and title
allsongs <- read.csv("1-tsort-chart-2-6-0013.csv")
#nsongs <- allsongs[,1:2]
rsongs <- allsongs[,1:3]
#Split data into just songs and albums
justsongs<- rsongs[(rsongs$type=="song"),]
justalbums <- rsongs[(rsongs$type=="album"),]
#Set as characters
csongs <- as.character(justsongs$name)
calbums <- as.character(justalbums$name)
#Make sure song names are in correct format
csongs <- tolower(csongs)
csongs <- str_extract_all(csongs, boundary("word"))
calbums <- tolower(calbums)
calbums <- str_extract_all(calbums, boundary("word"))


#Empty list for words
words <- list()
#Function looks at song titles, splits them up into words, adds them to a list and keeps track of number 
for (x in 1:length(csongs)){
  title <- csongs[[x]]
  #Iterate through title
  for (y in 1:length(title)){
    word <- title[[y]]
    #check if the word is in the list and gives it a count value
    if(exists(word, words)){
      words[[word]] <- words[[word]] + 1
    }else{
      words[[word]] <- 1
    }
  }
}
#Didn't do analysis on this one, so not important
#worda <- list()
#Function looks at song titles, splits them up into words, adds them to a list and keeps track of number
#top5 <- as.character(top5000$name)
#Make sure song names are in correct format
#top5 <- tolower(top5)
#top5 <- str_extract_all(csongs, boundary("word"))
#dtfa <- data.frame()
#for (b in 1:length(calbums)){
#  titlea <- calbums[[b]]
#  for (c in 1:length(titlea)){
#    aword <- titlea[[c]]
#    if(exists(aword, worda)){
#      worda[[aword]] <- worda[[aword]] + 1
#    }else{
#      worda[[aword]] <- 1
#    }
#  }
#}


#Formatting Data and saving
mdf <- as.data.frame(words)
gmdf <- t(mdf)
colnames(gmdf) <- c("Instances")
write.table(gmdf, file = "songvalues.csv")
#didn't use
#formatting album data
#mdfa <- as.data.frame(worda)
#gmdfa <- t(mdfa)
#colnames(gmdfa) <- c("Instances")
#write.table(gmdfa, file = "albumvalues.csv")

top5 <- read.csv("2-top5000songs-2-6-0013.csv")
top5 <- as.character(top5000$name)
top5 <- tolower(top5)
top5 <- str_extract_all(csongs, boundary("word"))
#get the word count of top 5000
wordcount <- function(list){
  #Did two << to save as a global variable, to track progress
  words <<- list()
  dtf <<- data.frame()
  for (x in 1:length(list)){
    title <<- list[[x]]
      for (y in 1:length(title)){
        word <<- title[[y]]
        if(exists(word, words)){
          words[[word]] <<- words[[word]] + 1
    }   else{
          words[[word]] <<- 1
    }
  }
  }
}
#Did the same thing as word coutns for big dataframe
mdf <- as.data.frame(words)
gmdf5 <- t(mdf)
colnames(gmdf5) <- c("Instances")
write.table(gmdf5, file = "songvalues5000.csv")


# Take numeric vector, spit out z-scores
# Use this to compare US score to Europe score (for example), since they have different ranges
zscores <- function(numData) {
  m <- mean(numData, na.rm = TRUE)
  sd <- sd(numData, na.rm = TRUE)
  z <- (numData - m)/sd
  return(z)
}

withztes <- read.csv("2-top5000songs-2-6-0013.csv")
# Add z-scores to the data
withztes$z_usa <- zscores(top5000$raw_usa)
withztes$z_eng <- zscores(top5000$raw_eng)
withztes$z_eur <- zscores(top5000$raw_eur)
withztes$z_row <- zscores(top5000$raw_row)

corectv5tes <- gmdf5
#Search through 5000 for words and get their values, make sure correct format
corectv5tes$word <- as.character(corectv5tes$word)
withztes$name <- as.character(withztes$name)
corectv5tes$word <- str_extract_all(corectv5tes$word, boundary("word"))
withztes$name <- tolower(withztes$name)
corectv5tes$word <- str_extract_all(corectv5tes$word, boundary("word"))


#colnames(corectv5[3:6]) <- c("U.S","Eng","Eur","Row")
score <- 0
mean <- 0
#Replaced the columns each time
#Get the average score per word
for (x in 1:3452){
  #doesn't return duplicates
  wappear <- grep(corectv5tes$word[[x]], withztes$name)
  for(y in wappear){
    score <- sum(withztes$z_row[[y]], na.rm = TRUE)
    mean <- mean + 1
    }
  scorer <- (score/mean)
  corectv5tes$Row[[x]] <- scorer
  score <- 0
      
    
  }
case <- corectv5tes
#wasn't formatted correctly so used original songs
valuetable <- corectv5tes[,3:6]
corectv5help[,3:6] <- valuetable
write.table(corectv5help,"5000popularitywords.csv")


#Didn't work out for meta data
#Ignore
#dat <-  readLines("metadata5000e.txt")
#dats <- str_split(dat, ':')
#9,22/28, 71/74/77, 83
#Mood, Tempo, Stlye, Male or Female
#datsq <- lapply(dats, noquote)
#datsqe <- str_extract_all(datsq, boundary("word"))
#tese <- unlist(datsq)
#sapply(datsq[[7]], grepl, "mood")
#datsq[[1]] <- NULL
#tester <- datsq[[1]]
#emptyl <- list()
#nob <- list()
#for(x in 1:length(datsq)){
#  nob[[x]] <- gsub("\\{|\\}", "", datsq[[x]])
#}
#nextes <- nob[[1]]

```

##Reading json Gracenote metadata as a table, cleaning it up
```{r eval=FALSE}
library(jsonlite)
##  https://cran.r-project.org/web/packages/jsonlite/index.html
##  https://cran.r-project.org/web/packages/jsonlite/jsonlite.pdf
library(dplyr)
##  https://cran.r-project.org/web/packages/dplyr/index.html
##  https://cran.r-project.org/web/packages/dplyr/dplyr.pdf
library(tidyr)
##  https://cran.r-project.org/web/packages/tidyr/index.html
##  https://cran.r-project.org/web/packages/tidyr/tidyr.pdf


json = fromJSON(paste("[",paste(
  readLines("https://raw.githubusercontent.com/MusicProject255/MusicResearch/master/Databases/meta.json"),
  collapse=","),"]"))

gracenote <- data.frame(json)

# Looking at the data, we have some nested data frames

gn <- flatten(gracenote)
tbl_df(gn)
# The 'tracks' column is still a list, but we don't need it, so...
gn <- gn %>% select(-tracks)
# We just take it out. Now we can write to csv.
write.csv(gn, "gnMetadata5000.csv")
```

##Merging Datasets
```{r eval=FALSE}
library(dplyr)
library(tidyr)

# Read in the old tsort data
top5000 <- read.csv("top5000.csv")

# Read in the new Gracenote metadata (still messy)
gnUnclean <- read.csv("gnMetadata5000.csv")

# Check it out.
tbl_df(gnUnclean)
View(gnUnclean)

# There are several columns containing urls (album art, album review). Drop those.
# There are also a bunch of ID columns (an index for different tempi, genres, etc.).
# IDs are probably useful for Gracenote, but I think we'll stick with English words. Drop those.
# Drop columns of NAs, and other stuff that just doesn't make any sense.
uselessCols <- c("album_art_url", "artist_bio_url", "radio_id", "track_artist_name", "artist_image_url",
                 "album_gnid", "xid", "review_url", "mood.1.ID", "mood.2.ID", "artist_era.1.ID",
                 "artist_era.2.ID", "tempo.1.ID", "tempo.2.ID", "tempo.3.ID", "artist_origin.1.ID",
                 "artist_origin.2.ID", "artist_origin.3.ID", "artist_origin.4.ID", "genre.1.ID",
                 "genre.2.ID", "genre.3.ID", "artist_type.1.ID", "artist_type.2.ID", "track_gnid")

# A warning message should pop up if I got any of the column names wrong
gnCleaner <- select(gnUnclean, -one_of(uselessCols))
tbl_df(gnCleaner)

# Nice!
# There's a bit more cleaning that I could do, but I want to go ahead and merge this with
# the tsort data, so my groupmates can start playing with it.

# Now merge the datasets
top5000plus <- bind_cols(top5000, gnCleaner)
tbl_df(top5000plus)

# and write to CSVs
write.csv(top5000plus, "top5000plus.csv")
write.csv(gnCleaner, "gnCleaner.csv")

```

##Formating metadata
```{r eval=FALSE}
library(stringr)

top5meta <- read.csv("top5000plus.csv")
top5meta[,1:2] <- NULL
colnames(top5meta) <- 
c("artist" ,"name", "year","finalscore","rawusa","raweng","raweur","rawrow","zusa","zeng","zeur","zrow", "decade","mood1","mood2","artistera1","artistera2","tempo1","exacttempo","tempo2","artistorigin1","artistoriginspecific","artistorigin2","artistorigin4","genre1","genreSpec","genre2","artisttype1",
"artisttype2")
top5meta$tempo1 <- gsub(" Tempo", "" ,top5meta$tempo1)
#Not splitting up mood 2 by / or " "

#gets genre, mood, tempo, artist
#Not right
#wordstat <- function(word){
#  wholewordinfo <<- data.frame()
#  formt <- str_extract_all(tolower(top5meta$name), boundary("word"))
#  wordloc <- grep(word, formt)
#  for(x in wordloc){
#    wholewordinfo[x,1] <<- word
#    wholewordinfo[x,2] <<- top5meta$genre1[x]
#    wholewordinfo[x,3] <<- top5meta$genreSpec[x]
#    wholewordinfo[x,4] <<- top5meta$genre2[x]
#    wholewordinfo[x,5] <<- top5meta$mood1[x]
#    wholewordinfo[x,6] <<- top5meta$mood2[x]
#    wholewordinfo[x,7] <<- top5meta$tempo1[x]
#    wholewordinfo[x,8] <<- top5meta$exacttempo[x]
#    wholewordinfo[x,9] <<- top5meta$tempo2[x]
#    wholewordinfo[x,10] <<- top5meta$artisttype1[x]
#    wholewordinfo[x,11] <<- top5meta$artistera1[x] 
#  }
  
#}
#Gets the first column, next function (kinda) does the rest
wordvalue <- data.frame() 
wordstatr <- function(word){
  wordinfo <- vector()
  formt <- str_extract_all(tolower(top5meta$name), boundary("word"))
  wordloc <- grep(word, formt)
  for(x in wordloc){
    wordinfo <- append(wordinfo, as.character(top5meta$mood1[x]))
  
  }
  top <- names(which.max(table(wordinfo)))
  #some have NA values
  if(length(top) == 0){
    wordvalue[(nrow(wordvalue)+1),1] <<- word
    wordvalue[(nrow(wordvalue)),2] <<- NA

  }
  else{
    wordvalue[(nrow(wordvalue)+1),1] <<- word
    wordvalue[(nrow(wordvalue)),2] <<- top
  }
}

#Get word stats
wlist <- as.list(corectv5help[,1])
wordlistv <- lapply(wlist, wordstatr)

#backup <- wordv
#wordv <- backup
wordvalue <- backup
backup <- test
#Get the rest of information
rplace <- 0
getrest <- function(word,y){
  #Make new column
  wordinfo <- vector()
  formt <- str_extract_all(tolower(top5meta$name), boundary("word"))
  #Locate word
  wordloc <- grep(word, formt)
  #Iterate through locations and append data to list
  for(x in wordloc){
      wordinfo <- append(wordinfo, as.character(top5meta[[y]][x]))

  }
  wordvalue[,ncol(wordvalue)+1] <<- NA
  #Gets the max of a table, and its element
  top <- names(which.max(table(wordinfo)))
  rplace <- grep("", wordvalue[,ncol(wordvalue)])
  if(length(rplace) == 0 ){
    rplace <- 1
  }else{
    rplace <-  rplace + 1
    print(rplace)
  }
  
  #NAs
  if(length(top) == 0){
    #Grep finds how many elemnts are in the row, so it can index it properly
    wordvalue[rplace,(ncol(wordvalue))] <<- NA

  }
  else{
    wordvalue[rplace,(ncol(wordvalue))] <<- top
  }
}

#For this I manually put in the columns because the function didn't work as planned, I set y as the rows
#I want then format it as a dataframe and appen
cat <- lapply(wlist, getrest, y = 29)
#Put it as a dataframe to append to wordvalue
temp <- as.data.frame(do.call("rbind", cat), stringsAsFactors = FALSE)
backup[,14] <- temp
#dog <- t(wordvalue[, 3:3454])
right <- dog[,1]
colnames(wordvalue) <- c("word","mood1","mood2","era","tempo1","tempo2","tempo3","artistorigin1","artistorigin2","genre1","genre2","genre3","grouptype1","grouptype2","count")
#add z scores and count for each word
wordvalue[,16:19] <- corectv5tes[,3:6]
#As.character changed numbers in title so they are unsearchable
num <- grep("X", wordvalue$word)
#Remove them
test <- wordvalue[-rnum,]
#write.table(top5meta, "formattedtop5meta.csv")
#write.table(wordvalue, "wordvaluemeta.csv")
write.table(test, "actualraveragewordvalues.csv")
#Final dataframe
write.table(top5meta, "fin5000.csv")

```
##View of data

```{r}
wthzright  <- read.csv("top5000withz.csv")
head(wthzright)
values5000right <- read.csv("songvalues5000.csv")
head(values5000right)
corectv5right <- read.csv("5000popularitywords.csv")
head(corectv5right)
hereiswordv <- read.csv("wordvalue.csv")
head(hereiswordv)


```



## Looking at some plots
```{r}
library(ggplot2)
library(RColorBrewer)

# This function takes a genre, then shows a segmented bar chart, with decade on the x-axis, 
# and different moods as the segments. I use it in the Shiny app.
countsOf <- function(genre = "All") {
  data <- top5000f
  if (genre != "All") data <- filter(data, genre1 == genre)
  
  ggplot(data) +
    geom_bar(aes(x = as.character(decade), fill = mood1, colour = "black")) +
    guides(colour = FALSE, fill = guide_legend(title = NULL)) +
    labs(list(y = "Count", x = "Decade", title = paste("Moods of", genre, "Songs Through the Years"))) +
    theme(plot.title = element_text(hjust = 0.5))
}

# This is the other function I use in the Shiny app.
# It takes a genre and a mood (or "All") and produces a scatterplot of score versus year,
# with some contours shown for particularly dense places on the plot
plotScores <- function(genre = "All", mood = "All") {
  data <- top5000f
  if (genre != "All") data <- filter(data, genre1 == genre)
  if (mood != "All") data <- filter(data, mood1 == mood)
  
  data %>% ggplot(aes(year, finalscore, xmin = 1900, xmax = 2016, ymin = 0, ymax = 40), na.rm = TRUE) +
    geom_point() + 
    stat_density2d(aes(fill = ..level..), geom = "polygon", alpha = 0.3) +
    labs(list(y = "Score", x = "Year", title = paste(genre, "Songs with", mood, "Moods"))) +
    theme(plot.title = element_text(hjust = 0.5))
  
}

# This big block of code makes six bar charts (for the six most common genres)
# with decade on the x-axis and colored segments for mood
top5000f %>% filter(genre1 != "Classical" & 
                      genre1 != "Other" & 
                      genre1 != "Soundtrack" & 
                      genre1 != "Traditional" &
                      !is.na(genre1)) %>% 
  ggplot() +
  geom_bar(aes(x = as.character(decade), fill = mood1, colour = "black")) +
  scale_fill_manual(values = colorRampPalette(brewer.pal(12, "Paired"))(30)) +
  guides(colour = FALSE, fill = guide_legend(title = NULL)) +
  facet_wrap(~as.factor(genre1)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(y = "Count", x = "Decade")


```

## End goals
```{r}
write.table(goodOnes, "topaverages.csv")
second <- read.csv("6-songWordCounts.csv")
#graphing doesn't make sense
#ggplot(data = test, aes(x = mood1, y = U.S))+
  #geom_point()
#make a shiny that displays average word info

#The one hit wonders
library(ggrepel)
newdata <- doggo[order(-doggo$aveScore),]
gdata <- newdata[1:25,]
onehit <- ggplot(data = gdata, aes(x = counts, y = aveScore, label = word))+
  geom_text_repel(size=2)+
  labs(title="Words that appear few times, but have a high score")
#ggsave(filename="onehit.pdf", plot=onehit)
#Highest average over 20
goodone <- read.table("topaverages.csv")
ngdata <- goodone[order(-goodone$aveScore),]
ngdat <- ngdata[1:25,]
over20 <- ggplot(data= ngdat, aes(x = counts, y = aveScore, label = word))+
  geom_text_repel(size=2)+
  labs(title="Highest scoring words with 20 or more counts")
#ggsave(filename="over20.pdf", plot=over20)
#Highest counts
gplot <- goodone[1:25,]
highescount <- ggplot(data=gplot, aes(x = counts, y = aveScore, label=word)) +
  geom_text_repel(size=2)+
  labs(title="Words that appear the most")
#ggsave(filename="highestcount.pdf", plot=highescount)





```
